- Data Cleaning: Filter out special characters
- Bias: Check the model for bias
- Business Understanding:

    - Conversation AI: Vision

Globally, fewer people are silenced and more people are able to safely engage in good faith 
discussion online. Our team leads as an example of ethical practices in building technology.

Our Values

Community: Communities should responsibly shape their discussions.
Transparency: Open processes enable better outcomes and trust.
Inclusivity: Diverse points of view make discussions better.
Privacy: We are privacy conscious in design and execution.
Topic-neutral: Good faith discussion can happen on controversial topics.

- help online discussions, perspective API offered online for free for discussion board leaders to inlcude in their work
- updated challenge asks for classification of toxicity: identity, threats etc.
- where does the model go wrong? error analysis, is there a pattern in it that can be ruled out by adjusting the model
- 


- https://medium.com/neuralspace/are-you-indulging-in-a-toxic-conversation-c67708b8895
    -> toxic comment challenge with cross-lingual model

- https://www.scientificamerican.com/article/can-ai-identify-toxic-online-content/#
    -> 
    
- https://towardsdatascience.com/toxic-comment-classification-using-lstm-and-lstm-cnn-db945d6b7986
    -> challenge submission using lstm and cnn
    
https://www.ijrte.org/wp-content/uploads/papers/v10i1/A58140510121.pdf
    -> another useful paper that talks about the data


What has been done by other researchers in this challenge? 
- https://www.researchgate.net/publication/349929587_Machine_learning_methods_for_toxic_comment_classification_a_systematic_review/fulltext/6048146592851c077f2b0b29/Machine-learning-methods-for-toxic-comment-classification-a-systematic-review.pdf
     -> overview of different models used in this challenge


