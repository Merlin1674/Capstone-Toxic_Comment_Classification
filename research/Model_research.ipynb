{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef350b09-10ab-42d9-b075-1e2acd37b1a6",
   "metadata": {},
   "source": [
    "# Papers to NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ecfc1e-5be8-4449-bbbb-3ebcb2920ec3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Toxicity Detection for Indic Multilingual Social Media Content:\n",
    "https://arxiv.org/pdf/2201.00598.pdf\n",
    "#### Models\n",
    "* XLM-RoBERTa - It is a transformer-based masked language model trained on 100 languages, using more than two terabytes of filtered CommonCrawl data. [3]\n",
    "* mBERT - MultilingualBERT (mBERT) is a transformer based language model trained on raw Wikipedia text of 104 languages. This model is contextual and its training requires no supervision - no alignment between the languages is done. [5]\n",
    "* RemBERT - This model is pretrained on 110 languages using a Masked Language Modeling (MLM) objective. Its main difference with mBERT is that the input and output embeddings are not tied. Instead, RemBERT uses small input embeddings and large output embeddings. [2]\n",
    "\n",
    "#### Architecture\n",
    "MLM and Transliterated data had a positive impact on the performance.\n",
    "one was the original architecture where we took the transformer outputs and found the probabilities and in the second one, we added a custom attention head for the transformer output before calculating the probabilities.\n",
    "\n",
    "#### Data Augmentation\n",
    "We performed data augmentation by adding transliterated data. We removed emojis from text and then we used uroman1 to generate additional transliterated data of 219114 samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea65446-babd-4174-911e-16bc99f8a733",
   "metadata": {},
   "source": [
    "## A Survey of Toxic Comment Classification Methods\n",
    "\n",
    "https://arxiv.org/pdf/2112.06412.pdf\n",
    "### Preprocessing\n",
    "Regex to implement text normalization\\\n",
    "Tokenizer class from Keras library to vectorize a text corpus\\\n",
    "Padding strategy with pad_sequences function from Keras\n",
    "### Architecture\n",
    "preprocessing&Feature engineering --> embedding layer --> concolutional layer --> feed-forward layer --> output layer\n",
    "preprocessing&Feature engineering --> embedding layer --> LSTM layer --> output layer\n",
    "Naive Bayes: 96.8%\\\n",
    "LSTM(with FastText): 99.4 %\\\n",
    "LSTM(with GloVe): 99.6 %\\\n",
    "CNN(with FastText): 99.4 %\\\n",
    "CNN(with GloVe): 99.5\\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6744dfe0-e125-4966-a5c7-f6e3d60f680a",
   "metadata": {},
   "source": [
    "## Predicting Different Types of Subtle Toxicity in Unhealthy Online Conversations\n",
    "https://arxiv.org/pdf/2106.03952.pdf\n",
    "### Architecture\n",
    "Convolutional Neural Network Long Short Term Memory (CNN-LSTM) with pre-trained word embeddings. We used Global Vectors for Word Representation (GloVe; Pennington et al., 2014b) to create an index of words mapped to known embeddings by parsing the data dump of pre-trained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d632c10c-8f70-442b-a1e5-8330eed3a243",
   "metadata": {},
   "source": [
    "## UIT-ISE-NLP at SemEval-2021 Task 5: Toxic Spans Detection with BiLSTM-CRF and ToxicBERT Comment Classification\n",
    "https://arxiv.org/pdf/2104.10100.pdf\n",
    "### Architecture\n",
    "**Detection model:** BiLSTM-CRF is a deep neu- ral model used for Named-entity recognition task (Lample et al., 2016). We implement this model for the task of detecting toxic words in documents. The model includes three main layers: (1) The word representation layer uses embedding matrix from the GloVe word embedding, (2) The BiLSTM layer for sequence labeling, and (3) The Condi- tional Random Field (CRF) layer to control the probability of output labels.\\\n",
    "**Classification model:** The ToxicBERT model (Detoxify) is introduced by Hanu and Unitary team (2020) with the purpose to stop online abusive com- ments. It is a pre-trained model and is easy to use by using transformers library4. The model is trained on the Toxic Comments Classification Chal- lenge datasets provided by Jigsaw.\\\n",
    "Our system combines the detection and clas- sification model together. The detection model (BiLSTM-CRF) returns the toxic spans from the post, while the classification model (ToxicBERT) classifies whether a post is toxic or non-toxic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9af9da-1f55-4b10-97dc-33d3ed951a96",
   "metadata": {},
   "source": [
    "## Is preprocessing of text really worth your time for toxic comment classification?\n",
    "https://arxiv.org/pdf/1806.02908.pdf\n",
    "\n",
    "### Models\n",
    "1) Logistic regression, which is conventionally used in sentiment classification.\n",
    "2) Naive Bayes with SVM (NBSVM), \n",
    "3) Extreme Gradient Boosting (XGBoost) and \n",
    "4) FastText algorithm with Bidirectional LSTM (FastText-BiLSTM).\n",
    "\n",
    "The F1-score for negative class is somewhere around 0.8 for NBSVM and fastText-BiLSTM, for logit this value is around 0.74 and for XGBoost, the value is around 0.57. The fastText-BiLSTM and NBSVM performed consistently well for most of the transformations compared to the Logit and XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f496fdca-55d5-4142-82ca-cbcb45b296b2",
   "metadata": {},
   "source": [
    "## Empirical Analysis of Multi-Task Learning for Reducing Identity Bias in Toxic Comment Detection\n",
    "https://arxiv.org/pdf/1909.09758.pdf\n",
    "\n",
    "Embedding layer --> biLSTM layer --> attention layer (two fully connected layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f32aa1b-070d-4816-9c6e-39b69f801929",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LONG RANGE ARENA: A BENCHMARK FOR EFFICIENT TRANSFORMERS\n",
    "https://arxiv.org/pdf/2011.04006.pdf\n",
    "\n",
    "**Results on Text Classification:** Byte-level classification is shown to be difficult and challenging especially when no pretraining or contextual embeddings are used. The best model only obtains 65.90 accuracy. The Linear Transformer performs well on this task, along with the Performer model. Contrary to the ListOps task, it seems like fast kernel-based models do well on this task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ea39f4-0edc-40e2-b85a-45f69802b208",
   "metadata": {},
   "source": [
    "# ****BiLSTM & Attention Layer****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798192f0-c0f8-408d-a580-2387ac8844c4",
   "metadata": {},
   "source": [
    "## A Beginner’s Guide to Using Attention Layer in Neural Networks\n",
    "https://analyticsindiamag.com/a-beginners-guide-to-using-attention-layer-in-neural-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24568f54-56e7-450b-b88e-a9b8c4e69dcc",
   "metadata": {},
   "source": [
    "## Hands-On Guide to Bi-LSTM With Attention\n",
    "https://analyticsindiamag.com/hands-on-guide-to-bi-lstm-with-attention/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c53ad8a-5a7c-40f6-96b8-a1c4e2d7b242",
   "metadata": {},
   "source": [
    "## biLSTM for multilabel toxic comments\n",
    "https://medium.com/analytics-vidhya/author-multi-class-text-classification-using-bidirectional-lstm-keras-c9a533a1cc4a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8359ed8b",
   "metadata": {},
   "source": [
    "# ****Data Augmentation****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3851ca",
   "metadata": {},
   "source": [
    "## Can We Achieve More with Less? Exploring Data Augmentation for Toxic Comment Classification\n",
    "https://arxiv.org/pdf/2007.00875.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22b4b12",
   "metadata": {},
   "source": [
    "# Text Augmentation for Neural Networks\n",
    "http://ceur-ws.org/Vol-2268/paper11.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72baf99e",
   "metadata": {},
   "source": [
    "# ****Benchmark model of Toxic comment****"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df76f74a",
   "metadata": {},
   "source": [
    "## Kaggle 3rd Place Solution — Jigsaw Multilingual Toxic Comment Classification\n",
    "https://towardsdatascience.com/kaggle-3rd-place-solution-jigsaw-multilingual-toxic-comment-classification-e36d7d194bfb\n",
    "\n",
    "https://github.com/moizsaifee/kaggle-jigsaw-multilingual-toxic-comment-classification-3rd-place-solution\n",
    "\n",
    "Multimodel (RoBERTa, RoBERTA++, RoBERTa MLM, Mono BER) and blending (weighted average)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214e107e",
   "metadata": {},
   "source": [
    "## Video of the challenge winners:\n",
    "https://www.youtube.com/watch?v=_-VeZU4JyBo\n",
    "\n",
    "Basic Model:\n",
    "* Word embeddings\n",
    "* Two BiGru layers\n",
    "* Two dense layers\n",
    "* Output\n",
    "\n",
    "a. Diverse pre-trained embeddings (FassTest & Glove)\n",
    "b. Translationa as train/**test** augmentation\n",
    "c. Pseudo labeling (trained test date with best ensemlbe than train on that)\n",
    "d Robust CV + stacking frameworf (used a mix of arithmetic averaging and LightGBM)\n",
    "\n",
    "Also: train on translation...\n",
    "\n",
    "https://www.meetup.com/LearnDataScience/events/248699439/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
