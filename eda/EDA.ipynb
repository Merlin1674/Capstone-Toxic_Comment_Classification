{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the necessary libraries and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# For visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from matplotlib_venn import venn3\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"train.csv\"\n",
    "data = pd.read_csv(PATH)\n",
    "print(\"Shape of data=>\",data.shape)\n",
    "# list of categories\n",
    "cat = data.columns.tolist()[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First draft visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the frequency of each category\n",
    "df = pd.melt(data,\n",
    "             id_vars=['id'],\n",
    "             value_vars = cat,\n",
    "             var_name = 'Category',\n",
    "             value_name = 'Count')\n",
    "df = df.loc[df.Count>0]\n",
    "ax = sns.countplot(x='Category', data=df)\n",
    "for p in ax.patches: \n",
    "    ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.15, p.get_height()+1)) \n",
    "plt.xticks(rotation=45, fontsize=12, ha=\"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the counts of multilabled comments\n",
    "data['label_count'] = data['toxic'] + data['severe_toxic'] + data['obscene'] + data['threat'] + data['insult'] + data['identity_hate']\n",
    "ax = sns.countplot(x='label_count', data=data[data['label_count'] > 0])\n",
    "for p in ax.patches: \n",
    "    ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.15, p.get_height()+0.01)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating word clouds for each category\n",
    "source for wordcloud above: https://www.geeksforgeeks.org/generating-word-cloud-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting word clouds for each category\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "axes = []\n",
    "fig = plt.figure(figsize=(25, 15))\n",
    "for a in range(len(cat)):\n",
    "    comment_words = ''\n",
    "    subdata = data[(data[cat[a]] == 1)]\n",
    "    for t_text in subdata.comment_text:\n",
    "        # typecaste each val to string\n",
    "        t_text = str(t_text)\n",
    "        # split the value\n",
    "        tokens = t_text.split()\n",
    "        # Converts each token into lowercase\n",
    "        for i in range(len(tokens)):\n",
    "            tokens[i] = tokens[i].lower()\n",
    "        comment_words += \" \".join(tokens)+\" \"\n",
    "    wordcloud = WordCloud(width = 800, height = 800,\n",
    "                    background_color ='black',\n",
    "                    stopwords = stopwords,\n",
    "                    min_font_size = 10).generate(comment_words)\n",
    "    # plot the WordCloud images\n",
    "    axes.append(fig.add_subplot(2, 3, a+1))\n",
    "    subplot_title=(cat[a])\n",
    "    axes[-1].set_title(subplot_title, fontsize=40) \n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")      \n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average length of comments due to their category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get average number of words per comment\n",
    "\n",
    "def get_avg_word_num(data):\n",
    "    final_count = []    \n",
    "    for i in range(len(data)):\n",
    "        words = data['comment_text'].iloc[i].split()\n",
    "        final_count.append(len(words))\n",
    "    avg = sum(final_count) / len(final_count)    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_data = data[(data['toxic'] == 1)]\n",
    "sev_tox_data = data[(data['severe_toxic'] == 1)]\n",
    "obs_data = data[(data['obscene'] == 1)]\n",
    "threat_data = data[(data['threat'] == 1)]\n",
    "insult_data = data[(data['insult'] == 1)]\n",
    "identity_data = data[(data['identity_hate'] == 1)]\n",
    "non_toxic_data = data[(data['toxic'] == 0) & (data['severe_toxic'] == 0) & (data['obscene'] == 0) & (data['threat'] == 0) & (data['insult'] == 0) & (data['identity_hate'] == 0)]\n",
    "\n",
    "all_dfs = [non_toxic_data, toxic_data, sev_tox_data, obs_data, threat_data, insult_data, identity_data]\n",
    "\n",
    "sev_tox_data.name = 'severe_toxic'\n",
    "toxic_data.name = 'toxic'\n",
    "obs_data.name = 'obscene'\n",
    "threat_data.name = 'threat'\n",
    "insult_data.name = 'insult'\n",
    "identity_data.name = 'identity_hate'\n",
    "non_toxic_data.name = 'non_toxic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_word_count = []\n",
    "df_names = []\n",
    "for df in all_dfs:\n",
    "        avg_word_count.append(get_avg_word_num(df))\n",
    "        df_names.append(df.name)\n",
    "sns.barplot(df_names, avg_word_count)\n",
    "plt.xticks(rotation=45, fontsize=12, ha=\"right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Venn-Diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = data[(data['toxic'] == 1) & (data['insult'] == 0) & (data['obscene'] == 0)].shape[0]\n",
    "i = data[(data['toxic'] == 0) & (data['insult'] == 1) & (data['obscene'] == 0)].shape[0]\n",
    "o = data[(data['toxic'] == 0) & (data['insult'] == 0) & (data['obscene'] == 1)].shape[0]\n",
    "\n",
    "t_i = data[(data['toxic'] == 1) & (data['insult'] == 1) & (data['obscene'] == 0)].shape[0]\n",
    "t_o = data[(data['toxic'] == 1) & (data['insult'] == 0) & (data['obscene'] == 1)].shape[0]\n",
    "i_o = data[(data['toxic'] == 0) & (data['insult'] == 1) & (data['obscene'] == 1)].shape[0]\n",
    "\n",
    "t_i_o = data[(data['toxic'] == 1) & (data['insult'] == 1) & (data['obscene'] == 1)].shape[0]\n",
    "\n",
    "\n",
    "# Make the diagram\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Venn diagram for 'toxic', 'insult' and 'obscene'\")\n",
    "venn3(subsets = (t, i, t_i, o, t_o, i_o, t_i_o), \n",
    "      set_labels=('toxic', 'insult', 'obscene'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "608d152bbf98f7f2b52d07aed6b0e90f779ffd266861d2996d035937a3571f82"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
