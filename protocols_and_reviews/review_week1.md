# Protocol Week 1

## overall ideas 
- Data Cleaning: Filter out special characters
- Check the model for unintended bias:
    - [Link](https://github.com/conversationai/unintended-ml-bias-analysis) 
- Toxic Comment Challenge using a cross-lingual model:
    - [Link](https://medium.com/neuralspace/are-you-indulging-in-a-toxic-conversation-c67708b8895)
- example challenge submission using lstm and cnn:
    - [Link](https://towardsdatascience.com/toxic-comment-classification-using-lstm-and-lstm-cnn-db945d6b7986)   
- another useful paper that talks about the data:
    - [Link](https://www.ijrte.org/wp-content/uploads/papers/v10i1/A58140510121.pdf)
- overview of different models used in this challenge:
    - [Link](https://www.researchgate.net/publication/349929587_Machine_learning_methods_for_toxic_comment_classification_a_systematic_review/fulltext/6048146592851c077f2b0b29/Machine-learning-methods-for-toxic-comment-classification-a-systematic-review.pdf)


## Business Understanding:

- From Conversation AI: 

_Our Vision_:

Globally, fewer people are silenced and more people are able to safely engage in good faith 
discussion online. Our team leads as an example of ethical practices in building technology.

_Our Values_:

Community: Communities should responsibly shape their discussions.
Transparency: Open processes enable better outcomes and trust.
Inclusivity: Diverse points of view make discussions better.
Privacy: We are privacy conscious in design and execution.
Topic-neutral: Good faith discussion can happen on controversial topics.

- More Thoughts on Business Understanding:
    - help moderate online discussions
    - perspective API offered online for free for discussion board leaders to inlcude in their work:
        - https://www.perspectiveapi.com/
    - Reasoning for using ML to detect toxicity in comments:
        - [Link](https://www.scientificamerican.com/article/can-ai-identify-toxic-online-content/#)



