{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0995638-5c2a-4672-976d-cd6ce1b3232a",
   "metadata": {},
   "source": [
    "# Transformer\n",
    "\n",
    "What is a Transformer?\n",
    "\n",
    "A Transformer is a type of neural network architecture developed by Vaswani et al. in 2017.\n",
    "Without going into too much detail, this model architecture consists of a multi-head self-attention mechanism combined with an encoder-decoder structure. It can achieve SOTA results that outperform various other models leveraging recurrent (RNN) or convolutional neural networks (CNN) both in terms of evaluation score (BLEU score) and training time.\n",
    "\n",
    "The Transformer model structure has largely replaced other NLP model implementations such as RNNs.\n",
    "The GPT model only uses the decoder of the Transformer structure (unidirectional), while **BERT** is based on the Transformer encoder (bidirectional).\n",
    "\n",
    "Many Transformer-based NLP models were specifically created for transfer learning. Transfer learning describes an approach where a model is first pre-trained on large unlabeled text corpora using self-supervised learning. \n",
    "\n",
    "While GPT used a standard language modeling objective which predicts the next word in a sentence, BERT was trained on Masked Language Modeling (MLM) and Next Sentence Prediction (NSP). The RoBERTa model replicated the BERT model architecture but changed the pre-training using more data, training for longer, and removing the NSP objective.\n",
    "\n",
    "The model checkpoints of the pre-trained models serve as the starting point for fine-tuning. A labeled dataset for a specific downstream task is used as training data. There are several different fine-tuning approaches, including the following:\n",
    "\n",
    "* Training the entire model on the labeled data.\n",
    "* Training only higher layers and freezing the lower layers.\n",
    "* Freezing the entire model and training one or more additional layers added on top.\n",
    "   \n",
    "No matter the approach, a task-specific output layer usually needs to be attached to the model. \n",
    "\n",
    "Source: [How to use transformer-based NLP models](https://towardsdatascience.com/how-to-use-transformer-based-nlp-models-a42adbc292e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b44247-442a-4f58-bf70-1431555bfd47",
   "metadata": {},
   "source": [
    "## Multilabel Classification with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557ca84b-3d10-4a95-a2ab-428909183198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install simpletransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2c89fc-fefe-4bc3-980d-586176cec48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gin-config\n",
    "!pip install tensorflow-addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69c672f-c90c-42b6-9f2d-ac7efe29e9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from itertools import cycle\n",
    "from simpletransformers.classification import MultiLabelClassificationModel\n",
    "from sklearn.metrics import accuracy_score, auc, classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db35172-38c9-404f-bc2c-154e98c34d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('../data/df_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ba9cc5-e73d-46a0-8f9a-8351cb4a10c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove new lines from comments\n",
    "df['comment_text'] = df.comment_text.apply(lambda x: x.replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156a568c-d9ff-4099-8a31-b82680e72215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# category list for plots\n",
    "categories = ['toxic', 'severe_toxic', 'obscene', 'threat',  'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be08bcad-3cee-439f-a385-f58c89b39064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataframe for train test split. MultilabelClassificator needs a text column and a labels column, \n",
    "# which provides all categories as a list\n",
    "new_df = pd.DataFrame()\n",
    "new_df['id'] = df['id']\n",
    "new_df['text'] = df['comment_text']\n",
    "new_df['labels'] = df.iloc[:, 2:8].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38772c38-268b-47ac-98ec-5ba5e265d697",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df):\n",
    "    train_df, eval_df = train_test_split(df, test_size=0.2, random_state=0)\n",
    "    return train_df, eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05efc95-b9ec-4f0f-ac97-4bbf26edb668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trand and eval df for the model training and evaluation\n",
    "train_df, eval_df = split(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458c5af0-f29c-4dba-a011-9eecb22dd908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model args\n",
    "args = {\n",
    "    'logging_steps': 10, \n",
    "    'overwrite_output_dir':True, \n",
    "    'train_batch_size':2, \n",
    "    'gradient_accumulation_steps':16, \n",
    "    'learning_rate': 3e-5, \n",
    "    'num_train_epochs': 4, \n",
    "    'max_seq_length': 128, \n",
    "    'wandb_project': 'toxic-comment-classification', \n",
    "    \"wandb_kwargs\": \n",
    "      {\"name\": \"bert-lr3e-5\"},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c2e775-5799-4281-bf6a-d09ff7ee9436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained model for the multilabel classification task\n",
    "model = MultiLabelClassificationModel('bert', 'bert-base-uncased', num_labels=6, args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d371654-7b4e-4c8f-8cad-72980d2b7d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model with the train data\n",
    "model.train_model(train_df = train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc7dc32-9eb5-4700-b66c-e0ee30a3cbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model, 'saved_models/bert_lr3e-5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb35da5-f2c5-41de-a44e-537f22b62b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = torch.load('saved_models/bert_lr3e-5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b85564-fd7e-479d-a61c-8468585cb1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model on eval_df\n",
    "result, model_outputs, wrong_predictions = model.eval_model(eval_df=eval_df, roc_auc_score=sklearn.metrics.roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541c84b3-8f8d-45b2-b170-20b8e7cf89ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "preds, outputs = model.predict(eval_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa9313f-bf8e-423a-877b-915500938e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define y_true for roc_auc plot and classification report\n",
    "y_true = np.array(eval_df['labels'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08213ed9-61a6-4c3b-a466-ab398e016f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_roc(probs, y_true, category, color):\n",
    "    \"\"\"\n",
    "    - Print AUC and accuracy on the test set\n",
    "    - Plot ROC\n",
    "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
    "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
    "    \"\"\"\n",
    "    preds = probs\n",
    "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    roc_aucs.append(roc_auc)\n",
    "    print(f'AUC: {roc_auc:.4f}')\n",
    "       \n",
    "    # Get accuracy over the test set\n",
    "    y_pred = np.where(preds >= 0.3, 1, 0)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "    \n",
    "    # Plot ROC AUC\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, color=color, label=\"{0} (area = {1:0.5f})\".format(category, roc_auc),)\n",
    "    plt.plot(fpr, tpr, color=color)\n",
    "    \n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'k--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.savefig('plots/roc_auc_curve.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9e0b45-431d-4459-8596-952185fbede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evalutae roc auc score and plot curves per category\n",
    "colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n",
    "\n",
    "for i, color in zip(range(6), colors):\n",
    "    print('-----------')\n",
    "    print(categories[i])\n",
    "    print('-----------')\n",
    "    evaluate_roc(outputs[:, i].ravel(), y_true[:, i].ravel(), categories[i], color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6189225-2562-4882-b973-ab576af20a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix per category\n",
    "y_test = np.array(eval_df['labels'].to_list())\n",
    "preds = np.array(preds)\n",
    "\n",
    "f, axes = plt.subplots(2, 3, figsize=(25, 15))\n",
    "axes = axes.ravel()\n",
    "for i in range(6):\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix(y_test[:, i],\n",
    "                                                   preds[:, i]),\n",
    "                                  display_labels=[f'non {categories[i]}', categories[i]])\n",
    "    disp.plot(ax=axes[i], values_format='.4g')\n",
    "    disp.ax_.set_title(f'toxicity label:\\n {categories[i]}', fontsize=20)\n",
    "    if i<3:\n",
    "        disp.ax_.set_xlabel('')\n",
    "    if i%3!=0:\n",
    "        disp.ax_.set_ylabel('')\n",
    "    disp.im_.colorbar.remove()\n",
    "\n",
    "plt.subplots_adjust(wspace=0.8, hspace=0.01)\n",
    "f.colorbar(disp.im_, ax=axes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab71ebd3-2c6c-435b-ae4b-4b16caa7e7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(f\"Classification Report : \\n\\n{classification_report(y_test, preds)}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3c9eb3-d52d-4dde-925a-08f0c556fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission_file\n",
    "test_df = pd.read_csv('data/test.csv')\n",
    "\n",
    "comments = test_df.comment_text.apply(lambda x: x.replace('\\n', ' ')).tolist()\n",
    "preds, outputs = model.predict(comments)\n",
    "\n",
    "submission = pd.DataFrame(outputs, columns=categories)\n",
    "\n",
    "\n",
    "submission['id'] = test_df['id']\n",
    "submission = submission[categories]\n",
    "\n",
    "# write to csv and upload at Kaggle to get ROC AUC Scores for Kaggles testdata\n",
    "submisssion.to_csv('/content/drive/MyDrive/data/submission_roberta_tuning_lr2e5.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
